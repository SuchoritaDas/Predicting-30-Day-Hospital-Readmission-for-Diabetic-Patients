# Predicting-30-Day-Hospital-Readmission-for-Diabetic-Patients

End-to-End Database + AI Project on Databricks

Domain: Healthcare Analytics
Platform: Databricks Lakehouse
Project Type: Data Engineering + Machine Learning
Sponsored by: Databricks
Powered by: Codebasics Ã— Indian Data Club

ğŸ“Œ Project Overview

Hospital readmission within 30 days is a critical indicator of healthcare quality, cost efficiency, and patient outcomes.
Diabetic patients experience significantly higher readmission rates due to chronic complexity, medication adjustments, and comorbidities.

This project presents a complete, production-style data and machine learning solution built on Databricks, designed to move from raw healthcare data to decision-ready insights using a structured Bronze â†’ Silver â†’ Gold architecture and an explainable ML model.

The focus is not only on prediction, but on:

Data reliability

Interpretability

Scalable architecture

Real-world healthcare impact

### ğŸ¯ Problem Statement (STAR â€“ Situation)

Hospitals are evaluated on 30-day readmission rates, which directly affect:

Quality-of-care metrics

Operational efficiency

Financial penalties and reimbursements

For diabetic patients, readmission rates are consistently higher than average, yet hospitals often lack:

A structured data pipeline to analyze historical admissions

A reliable way to identify high-risk patients before discharge

Explainable insights that clinicians and administrators can trust

Core Problem

How can hospitals use historical admission data to identify diabetic patients at high risk of 30-day readmission in a way that is scalable, interpretable, and actionable?

### ğŸ“Š Dataset Overview (STAR â€“ Situation)

Dataset: Diabetes 130-US Hospitals Dataset (Kaggle)

Time Period: 1999â€“2008

Records: ~100,000 hospital encounters

Granularity: One row per hospital admission

Key Categories of Columns

The dataset contains 50+ columns, broadly grouped as:

Patient demographics:
age, gender, race, weight

Admission & discharge details:
admission_type_id, admission_source_id, discharge_disposition_id, time_in_hospital, payer_code, medical_specialty

Clinical activity counts:
num_lab_procedures, num_procedures, num_medications,
number_outpatient, number_emergency, number_inpatient

Diagnosis information:
diag_1, diag_2, diag_3, number_diagnoses

Lab results:
max_glu_serum, A1Cresult

Medication indicators:
Diabetes drugs (metformin, insulin, glipizide, etc.), combination therapies, and medication change flags

Target variable:
readmitted_30 â†’ Whether the patient was readmitted within 30 days

This dataset reflects real hospital operations, making it suitable for healthcare risk modeling and decision support.

### ğŸ§© Task Definition (STAR â€“ Task)

The task was to design and implement:

A robust data architecture to handle raw healthcare data

A clean and validated dataset suitable for analytics and ML

An explainable machine learning model to predict 30-day readmission risk

A solution that mirrors real enterprise data platform practices

Success was defined not by model complexity, but by:

Correct data handling

Clear reasoning

Actionable insights

### ğŸ—ï¸ Solution Architecture (STAR â€“ Action)

The project follows a Databricks Lakehouse architecture with strict separation of responsibilities.

Raw CSV (Kaggle)
   â†“
Bronze Layer  â†’ Raw, immutable ingestion
   â†“
Silver Layer  â†’ Cleaned, validated, standardized data
   â†“
Gold Layer    â†’ Business-ready, ML-optimized dataset
   â†“
ML Training   â†’ Explainable model + MLflow tracking

### ğŸ“‚ Repository Structure

Each folder contains:

One Jupyter Notebook

One detailed README explaining that layer

â”œâ”€â”€ bronze/
â”‚   â”œâ”€â”€ BRONZE_LAYER.ipynb
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ silver/
â”‚   â”œâ”€â”€ SILVER_LAYER.ipynb
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ gold/
â”‚   â”œâ”€â”€ GOLD_LAYER.ipynb
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ ml_training/
â”‚   â”œâ”€â”€ ML_Training.ipynb
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ README.md  â† (this file)

## ğŸ” How the Project Was Implemented (STAR â€“ Action)

### ğŸ“¥ Data Ingestion & Environment Setup

The dataset was first downloaded as a CSV file from Kaggle and uploaded into the Databricks Free Edition workspace.

To maintain proper organization and data governance:

A dedicated catalog, schema, and volume were created for the project

The CSV file was uploaded using the Databricks Catalog interface

This allowed the data to be accessed directly within notebooks as a table source

This step reflects a real-world data ingestion approach, where raw files are landed into a controlled storage layer before further processing.

Once the data was available inside Databricks, the Bronzeâ€“Silverâ€“Gold Medallion Architecture was implemented to structure the data pipeline.


### ğŸ¥‰ Bronze Layer

Raw CSV data ingested into Databricks volumes

Schema preserved exactly as received

No transformations applied

Ensures traceability and auditability

### ğŸ¥ˆ Silver Layer

Missing and inconsistent values handled

Categorical and numerical fields standardized

Target variable readmitted_30 engineered

Data quality and class distribution validated

### ğŸ¥‡ Gold Layer

Selection of clinically and operationally meaningful features

Removal of non-actionable or noisy columns

Creation of a stable, ML-ready dataset

### ğŸ¤– ML Training

Logistic Regression chosen for interpretability

Categorical encoding and feature scaling applied

Train/test split with class stratification

Evaluation using AUC

Feature importance extracted for explanation

Experiments and models tracked using MLflow

### ğŸ“˜ Key Terms & Concepts 

-- 1ï¸âƒ£ Logistic Regression

What it is
Logistic Regression is a statistical model used for binary classification problems, where the outcome has two possible values.

In this project
It predicts whether a diabetic patient will be:

1 â†’ Readmitted within 30 days

0 â†’ Not readmitted within 30 days

ğŸ§  Why Logistic Regression?

Transparent decision logic

Clinician-friendly interpretation

Suitable for healthcare risk scoring

Focuses on understanding risk drivers, not just prediction

In healthcare, explainability outweighs model complexity.

-- 2ï¸âƒ£ Probability (Prediction Output)

What it means
Instead of just saying â€œYesâ€ or â€œNo,â€ the model outputs a probability score between 0 and 1.

Example

0.82 â†’ High risk of readmission

0.18 â†’ Low risk of readmission

Why this matters
Hospitals can:

Set risk thresholds

Prioritize patients with the highest risk

-- 3ï¸âƒ£ Features (X)

What features are
Features are the input variables used by the model to make predictions.

In this project, features include

Patient age and demographics

Length of hospital stay

Number of diagnoses

Emergency and inpatient visit history

Medication and treatment indicators

Simple explanation

Features describe the patientâ€™s condition and hospital experience.

-- 4ï¸âƒ£ Target Variable (y)

What it is
The target variable is what the model is trying to predict.

In this project

readmitted_30


1 â†’ Patient was readmitted within 30 days

0 â†’ Patient was not readmitted

-- 5ï¸âƒ£ Coefficients (Feature Weights)

What coefficients mean
Coefficients indicate how strongly each feature influences the prediction.

Positive coefficient â†’ increases readmission risk

Negative coefficient â†’ decreases readmission risk

Example

number_inpatient with a high positive coefficient
â†’ Patients with prior hospitalizations are more likely to be readmitted

Why this is important
This makes the model explainable, which is critical in healthcare.

-- 6ï¸âƒ£ Feature Scaling (StandardScaler)

What it is
Feature scaling adjusts numerical values so that all features are on a similar scale.

Why itâ€™s needed
Some features have small ranges (e.g., days in hospital), others have large ranges (e.g., lab counts).
Without scaling, the model may behave incorrectly.

In simple words

Scaling ensures the model treats all features fairly.

-- 7ï¸âƒ£ Trainâ€“Test Split

What it is
The dataset is split into:

Training set â†’ used to train the model

Test set â†’ used to evaluate performance

Why itâ€™s important
Prevents the model from being evaluated on data it has already seen.

-- 8ï¸âƒ£ Class Imbalance

What it means
In healthcare data, most patients are not readmitted, while fewer are.

This creates an imbalance:

Many 0s (not readmitted)

Fewer 1s (readmitted)

Why it matters
Accuracy alone can be misleading.
Thatâ€™s why we use AUC, not just accuracy.

-- 9ï¸âƒ£ AUC (Area Under the ROC Curve)

This is VERY IMPORTANT

What AUC measures
AUC measures how well the model can separate high-risk patients from low-risk patients.

AUC = 0.5 â†’ Random guessing

AUC = 1.0 â†’ Perfect separation

In healthcare
AUC answers this question:

Can the model correctly rank patients by risk?

Why AUC is preferred

Handles class imbalance well

Focuses on ranking, not just correctness

One-line explanation

AUC measures how well the model distinguishes between patients who will be readmitted and those who will not.

-- ğŸ”Ÿ ROC Curve (Brief)

What it is
The ROC curve shows the trade-off between:

True positive rate (catching real readmissions)

False positive rate (false alarms)

Why it matters
Hospitals can adjust thresholds depending on how cautious they want to be.

-- 1ï¸âƒ£1ï¸âƒ£ MLflow

What it is
MLflow is a tool for tracking machine learning experiments.

In this project
It tracks:

Model performance (AUC)

Model versions

Parameters and artifacts

Why itâ€™s important

Reproducibility

Transparency

Professional ML lifecycle management

Simple explanation

MLflow helps keep a record of what models were trained and how well they performed.

-- 1ï¸âƒ£2ï¸âƒ£ Explainable ML (Why This Matters)

What it means
An explainable model allows humans to understand:

Which factors matter

How decisions are influenced

Why itâ€™s critical in healthcare

Clinicians need trust

Decisions affect patient outcomes

Regulations require transparency


### ğŸ“ˆ Outcomes & Impact (STAR â€“ Result)

-- Key Insights Identified

Prior inpatient visit history

Emergency visit frequency

Length of hospital stay

Number of diagnoses

Medication and treatment changes

-- Real-World Impact

This solution enables hospitals to:

Flag high-risk diabetic patients before discharge

Prioritize follow-up care and monitoring

Improve discharge planning

Reduce avoidable readmissions

Lower healthcare costs while improving outcomes

### ğŸ§° Tools & Technologies

Databricks Lakehouse

Delta Lake

PySpark

Python

Scikit-learn

MLflow

Unity Catalog

All tools were used in a production-aligned, disciplined manner.

### ğŸ™ Sponsors & Acknowledgements

Databricks â€” Platform sponsorship
Codebasics â€” Initiative and guidance
Indian Data Club â€” Community and support

This project was built as part of a hands-on Databricks challenge, emphasizing real-world workflows.

### ğŸ“Œ Final Note

This repository represents a complete project submission, showcasing:

Structured data engineering

Thoughtful analytics

Responsible machine learning

Clear business and healthcare impact

The focus throughout was clarity, discipline, and real-world relevance.

### ğŸ”— Portfolio & Contact

Portfolio: [https://codebasics.io/portfolio/Suchorita-Das]
LinkedIn: [(https://www.linkedin.com/in/suchorita-das )]
